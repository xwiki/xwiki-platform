<?xml version="1.1" encoding="UTF-8"?>

<!--
 * See the NOTICE file distributed with this work for additional
 * information regarding copyright ownership.
 *
 * This is free software; you can redistribute it and/or modify it
 * under the terms of the GNU Lesser General Public License as
 * published by the Free Software Foundation; either version 2.1 of
 * the License, or (at your option) any later version.
 *
 * This software is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this software; if not, write to the Free
 * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
 * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
-->

<xwikidoc version="1.5" reference="XWiki.PDFExport.Sheet" locale="">
  <web>XWiki.PDFExport</web>
  <name>Sheet</name>
  <language/>
  <defaultLanguage/>
  <translation>0</translation>
  <creator>xwiki:XWiki.Admin</creator>
  <parent>WebHome</parent>
  <author>xwiki:XWiki.Admin</author>
  <contentAuthor>xwiki:XWiki.Admin</contentAuthor>
  <version>1.1</version>
  <title/>
  <comment/>
  <minorEdit>false</minorEdit>
  <syntaxId>xwiki/2.1</syntaxId>
  <hidden>true</hidden>
  <content>{{velocity output="false"}}
#set ($sheetReference = 'XWiki.PDFExport.Sheet')
#set ($pdfElements = ['cover', 'toc', 'header', 'footer'])
#set ($pdfExportJobId = $request.jobId.split('/'))
#if ($pdfExportJobId)
  #set ($pdfExportJobStatus = $services.job.getJobStatus($pdfExportJobId))
  #set ($pdfExportJobRequest = $pdfExportJobStatus.request)
#else
  #set ($pdfExportJobStatus = $NULL)
  #set ($pdfExportJobRequest = $NULL)
#end

#macro (getPDFExportConfigFromRequest $pdfExportConfig)
  #if ($pdfExportJobRequest)
    #set ($discard = $pdfExportConfig.putAll({
      'template': $pdfExportJobRequest.template,
      'cover': $pdfExportJobRequest.isWithCover(),
      'toc': $pdfExportJobRequest.isWithToc(),
      'header': $pdfExportJobRequest.isWithHeader(),
      'footer': $pdfExportJobRequest.isWithFooter()
    }))
  #end
#end

#macro (renderPDFSheet $pdfExportConfig)
  #set ($discard  = $response.setContentType('text/html'))
  #set ($discard = $xwiki.ssx.use($sheetReference))
  ## Temporarily disable the JavaScript minification until we find a way to fix the following Closure Compiler error:
  ##   [JSC_DYNAMIC_IMPORT_USAGE] Dynamic import expressions cannot be transpiled.
  ## See https://github.com/google/closure-compiler/wiki/JS-Modules#dynamic-import-expressions
  ## See also https://github.com/google/closure-compiler/issues/2770 ([FEATURE] Support dynamic import)
  ## This error is unexpected considering that we disable the transpiling here
  ## https://github.com/xwiki/xwiki-platform/blob/xwiki-platform-15.7/xwiki-platform-core/xwiki-platform-skin/xwiki-platform-skin-skinx/src/main/java/com/xpn/xwiki/web/sx/JsExtension.java#L91-L97
  ## We're using STABLE as input ECMAScript version, see https://github.com/xwiki/xwiki-commons/blob/xwiki-commons-15.7/pom.xml#L2585
  ## which is probably lower than ECMAScript 2020 (ES11) when support for dynamic imports was introduced.
  ## See also https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/import
  ## and https://caniuse.com/?search=import()
  #set ($discard = $xwiki.jsx.use($sheetReference, {'minify': false}))
  #set ($discard = $xwiki.ssx.use($pdfExportConfig.template))
  #set ($discard = $xwiki.jsx.use($pdfExportConfig.template))
  ## Use the specified PDF file name as the title of the HTML page in order to have it suggested as file name when
  ## saving the PDF from the browser's Print Preview dialog.
  #if ($pdfExportJobRequest)
    #set ($title = $pdfExportJobRequest.fileName)
  #end
  ## Output the HTML header but without the garbage from the start of the BODY tag.
  #set ($htmlHeader = "#template('htmlheader.vm')")
  ## The PDF export doesn't target only the paper paged media, and we want to preserve the styles from the XWiki skin as
  ## much as possible.
  #set ($htmlHeader = $htmlHeader.replace('data-xwiki-paged-media="paper"', ''))
  #set ($headTagEnd = $htmlHeader.indexOf('&lt;/head&gt;'))
  #set ($bodyTagStart = $htmlHeader.indexOf('&lt;body'))
  #set ($bodyContentStart = $htmlHeader.indexOf('&gt;', $bodyTagStart) + 1)
  $htmlHeader.substring(0, $headTagEnd)
  &lt;script&gt;
  requirejs.config({
    ## When performing large multi-page exports the RequireJS timeout can be reached because there are many HTTP
    ## requests and the browser uses a limited pool to handle them. We noticed this problem on a PDF export with many
    ## live tables because they fetch their results pretty early, before many RequireJS modules are requested. In any
    ## case, we have the page ready timeout to stop the export in case it takes too much time to load the print preview
    ## page. We don't need another timeout for RequrieJS modules.
    waitSeconds: 0,
    ## PagedJS uses some utility functions that are not exposed by the RequireJS module, so we have to import them
    ## ourselves from the WebJar in order to be able to patch PagedJS bugs.
    config: {
      'pagedjs-module': {
        baseURL: $jsontool.serialize($services.webjars.url('org.webjars.npm:pagedjs', ''))
      }
    }
  });
  &lt;/script&gt;
  ## Inject the required skin extensions.
  $!pdfExportJobStatus.requiredSkinExtensions
  #clientSidePDFExportConfiguration()
  ## Start the BODY tag.
  $htmlHeader.substring($headTagEnd, $bodyContentStart)
  #set ($pdfTemplateObj = $xwiki.getDocument($pdfExportConfig.template).getObject('XWiki.PDFExport.TemplateClass'))
  #foreach ($element in $pdfElements)
    #if ($pdfExportConfig.get($element))
      #set ($output = "#renderPDFElement($pdfTemplateObj $element)")
      #set ($output = $output.trim())
      #if ($output != '')
        &lt;div class="pdf-$element"&gt;$output&lt;/div&gt;
      #end
    #end
  #end
  &lt;div id="xwikicontent"&gt;
    #renderPDFContent()
  &lt;/div&gt;
  ## Close the tags opened in htmlheader.vm
    &lt;/body&gt;
  &lt;/html&gt;
#end

#macro (clientSidePDFExportConfiguration)
  #set ($clientSideConfig = {
    'documents': [],
    'baseURL': $pdfExportJobRequest.baseURL
  })
  #foreach ($renderingResult in $pdfExportJobStatus.documentRenderingResults)
    #set ($discard = $clientSideConfig.documents.add({
      'reference': $services.model.serialize($renderingResult.documentReference, 'default'),
      'idMap': $renderingResult.idMap
    }))
  #end
  &lt;script id="pdfExportConfig" type="application/json"&gt;$jsontool.serialize($clientSideConfig).replace(
    '&lt;', '\u003C')&lt;/script&gt;
#end

#macro (renderPDFElement $pdfTemplateObj $element)
  #unwrapXPropertyDisplay($tdoc.display($element, $pdfTemplateObj))
#end

#macro (renderPDFContent)
  #if (!$pdfExportJobRequest.isWithTitle())
    ## The document renderer includes the document metadata in the rendering results only when document titles are
    ## displayed (because we should have a single metadata on a print page and the document title starts on a new print
    ## page, but also because the metadata can be used to tweak how the document title is displayed, e.g. to skip or
    ## reset heading numbering). We may still want to display the metadata for a single page export or for a multipage
    ## export without titles, but in this case the same metadata is going to be displayed on all print pages, and it
    ## comes from the target document on which the PDF export was triggered.
    #outputMetadataFromTargetDocument()
  #end
  #foreach ($renderingResult in $pdfExportJobStatus.documentRenderingResults)
    $renderingResult.getHTML()
  #end
#end

#macro (outputMetadataFromTargetDocument)
  #set ($metadata = {
    'class': 'hidden',
    'data-xwiki-document-reference': $services.model.serialize($doc.documentReference, 'default')
  })
  #set ($discard = $tdoc.display('metadata', $pdfTemplateObj))
  &lt;h1#foreach ($entry in $metadata.entrySet()) $escapetool.xml($entry.key)="$escapetool.xml($entry.value)"#end
    &gt;$escapetool.xml($tdoc.plainTitle)&lt;/h1&gt;
#end
{{/velocity}}

{{velocity wiki="false"}}
#if ($request.sheet == $sheetReference)
  ## Default PDF Export configuration.
  #set ($pdfExportConfig = {
    'template': 'XWiki.PDFExport.Template',
    'cover': true,
    'toc': true,
    'header': true,
    'footer': true
  })
  #getPDFExportConfigFromRequest($pdfExportConfig)
  #renderPDFSheet($pdfExportConfig)
#end
{{/velocity}}</content>
  <object>
    <name>XWiki.PDFExport.Sheet</name>
    <number>0</number>
    <className>XWiki.JavaScriptExtension</className>
    <guid>f47dbbaa-6eac-4125-ae06-954e5d92215a</guid>
    <class>
      <name>XWiki.JavaScriptExtension</name>
      <customClass/>
      <customMapping/>
      <defaultViewSheet/>
      <defaultEditSheet/>
      <defaultWeb/>
      <nameField/>
      <validationScript/>
      <cache>
        <cache>0</cache>
        <defaultValue>long</defaultValue>
        <disabled>0</disabled>
        <displayType>select</displayType>
        <freeText>forbidden</freeText>
        <largeStorage>0</largeStorage>
        <multiSelect>0</multiSelect>
        <name>cache</name>
        <number>5</number>
        <prettyName>Caching policy</prettyName>
        <relationalStorage>0</relationalStorage>
        <separator> </separator>
        <separators>|, </separators>
        <size>1</size>
        <unmodifiable>0</unmodifiable>
        <values>long|short|default|forbid</values>
        <classType>com.xpn.xwiki.objects.classes.StaticListClass</classType>
      </cache>
      <code>
        <contenttype>PureText</contenttype>
        <disabled>0</disabled>
        <editor>PureText</editor>
        <name>code</name>
        <number>2</number>
        <prettyName>Code</prettyName>
        <restricted>0</restricted>
        <rows>20</rows>
        <size>50</size>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.TextAreaClass</classType>
      </code>
      <name>
        <disabled>0</disabled>
        <name>name</name>
        <number>1</number>
        <prettyName>Name</prettyName>
        <size>30</size>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.StringClass</classType>
      </name>
      <parse>
        <disabled>0</disabled>
        <displayFormType>select</displayFormType>
        <displayType>yesno</displayType>
        <name>parse</name>
        <number>4</number>
        <prettyName>Parse content</prettyName>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.BooleanClass</classType>
      </parse>
      <use>
        <cache>0</cache>
        <disabled>0</disabled>
        <displayType>select</displayType>
        <freeText>forbidden</freeText>
        <largeStorage>0</largeStorage>
        <multiSelect>0</multiSelect>
        <name>use</name>
        <number>3</number>
        <prettyName>Use this extension</prettyName>
        <relationalStorage>0</relationalStorage>
        <separator> </separator>
        <separators>|, </separators>
        <size>1</size>
        <unmodifiable>0</unmodifiable>
        <values>currentPage|onDemand|always</values>
        <classType>com.xpn.xwiki.objects.classes.StaticListClass</classType>
      </use>
    </class>
    <property>
      <cache>long</cache>
    </property>
    <property>
      <code>// Replace 'paged-polyfill' with 'paged-polyfill-patched' for everyone, except for 'paged-polyfill-patched'.
require.config({
  map: {
    '*': {
      'paged-polyfill': 'paged-polyfill-patched'
    },
    'paged-polyfill-patched': {
      'paged-polyfill': 'paged-polyfill'
    }
  }
});

// PagedJS uses some utility functions that are not exposed by the RequireJS module, so we have to import them
// ourselves in order to be able to patch PagedJS bugs.
define('pagedjs-module', ['module'], function(module) {
  return {
    load: function (name, req, onload, config) {
      import(module.config().baseURL + name).then(onload);
    }
  };
});

/**
 * We have to patch Paged.js in order to fix various issues.
 */
define('paged-polyfill-patched', [
  'paged-polyfill',
  'pagedjs-module!src/utils/utils.js',
  'pagedjs-module!src/utils/dom.js'
], function(PagedPolyfill, Utils, DOMUtils) {
  /**
   * This is a workaround for the Chrome / Paged.js bug that makes table rows hidden when they are split between print
   * pages. See https://github.com/pagedjs/pagedjs/issues/114 . See also https://jira.xwiki.org/browse/XWIKI-20741 .
   * TODO: Remove this hack once we upgrade to Paged.js 0.5.0 (as it seems the beta version is fixing the problem).
   *
   * See also https://pagedjs.org/documentation/10-handlers-hooks-and-custom-javascript/
   */
  class ShowInvisibleRowsOnPageBreaks extends Paged.Handler {
    constructor(chunker, polisher, caller) {
      super(chunker, polisher, caller);
    }

    afterPageLayout(pageFragment, page) {
      // We don't need the column display once the print page layout is done, but we need to make sure the page content
      // doesn't overflow the page footer.
      page.area.style.columnWidth = 'unset';
      page.area.style.overflow = 'hidden';
    }
  }

  /**
   * This is a workaround for https://github.com/pagedjs/pagedjs/issues/153 (Floating images are always included in the
   * current print page, even when they don't fit). We remove the floating style before the content is split into print
   * pages and restore it afterwards. The downside is that we get some empty space at the end of the print page
   * (proportional to the image size) but at least we don't loose data.
   */
  class FixFloatingImages extends Paged.Handler {
    constructor(chunker, polisher, caller) {
      super(chunker, polisher, caller);
    }

    beforeParsed(content) {
      // Look for floating images that were inserted by the user (using wiki syntax).
      content.querySelectorAll([
        '#xwikicontent img[data-xwiki-image-style-alignment="start"]',
        '#xwikicontent img[data-xwiki-image-style-alignment="end"]',
        '#xwikicontent img[data-xwiki-image-style-text-wrap="true"]'
      ].join()).forEach((floatingImage) =&gt; {
        // Save the current float value (to be restored after the content is split into print pages).
        floatingImage.setAttribute('data-xwiki-export-pdf-original-float', floatingImage.style.cssFloat);
        // Remove the floating style.
        floatingImage.style.cssFloat = 'none';
      });
    }

    afterRendered(pages) {
      pages.forEach((page) =&gt; {
        page.area.querySelectorAll('[data-xwiki-export-pdf-original-float]').forEach((element) =&gt; {
          // Restore the original floating style.
          element.style.cssFloat = element.getAttribute('data-xwiki-export-pdf-original-float');
          element.removeAttribute('data-xwiki-export-pdf-original-float');
        });
      });
    }
  }

  /**
   * Make sure the table rows are complete before determining the overflow otherwise the table layout is different than
   * in view mode. See XWIKI-21043 (The last lines of text from a print page are not always visible when they are inside
   * a table cell that is split between print pages).
   *
   * TODO: Remove this code when the following issues get fixed:
   * &lt;ul&gt;
   *   &lt;li&gt;&lt;a href="https://github.com/pagedjs/pagedjs/issues/157"&gt;#157: The last line of text from a print page is
   *     sometimes not fully visible&lt;/a&gt;&lt;/li&gt;
   *   &lt;li&gt;&lt;a href="https://github.com/pagedjs/pagedjs/issues/154"&gt;#154: Text gets truncated at the end of the page when
   *     a long table is split&lt;/a&gt;&lt;/li&gt;
   * &lt;/ul&gt;
   */
  class FixTableLayout extends Paged.Handler {
    constructor(chunker, polisher, caller) {
      super(chunker, polisher, caller);
    }

    layout(renderedContent, layoutMethod) {
      if (typeof layoutMethod.rebuildTableRows === 'function') {
        // Layout already patched.
        return;
      }

      layoutMethod.rebuildTableRows = function (rendered, source) {
        rendered.querySelectorAll("tr").forEach((renderedRow) =&gt; {
          const sourceRow = DOMUtils.findElement(renderedRow, source, true);
          // Skip if the row is fully rendered.
          if (!sourceRow || renderedRow.childNodes.length &gt;= sourceRow.childNodes.length) {
            return;
          }
          // Otherwise, we will append the missing cells. Note that we perform a deep clone of the missing cells
          // because we don't want them to be skipped (if empty) when finding the overflow point (since this method is
          // normally called right before the overflow is computed).
          const sourceCells = [...sourceRow.childNodes];
          for (let i = renderedRow.childNodes.length; i &lt; sourceCells.length; i++) {
            this.append(sourceCells[i], rendered, null, false);
          }
        });
      };

      const originalFindBreakToken = layoutMethod.findBreakToken;
      layoutMethod.findBreakToken = function(rendered, source) {
        // Make sure the table rows are complete before determining the overflow, otherwise the table layout will be
        // different than on the source document (e.g. different column widths). Moreover, we're rebuilding the table
        // rows also after removing the overflown content for the same reason, to ensure the table layout is preserved.
        this.rebuildTableRows(rendered, source);
        return originalFindBreakToken.apply(this, arguments);
      };

      const originalAppend = layoutMethod.append;
      layoutMethod.append = function(node, dest, breakToken, shallow = true, rebuild = true) {
        // Check if the node is already appended.
        if (DOMUtils.isElement(node)) {
          // If the node is an element then we can look directly for it (based on data-ref attribute).
          const existingElement = DOMUtils.findElement(node, dest, true);
          if (existingElement) {
            // The element is already appended, but maybe it was a shallow clone.
            if (!shallow &amp;&amp; node.hasChildNodes() &amp;&amp; !existingElement.hasChildNodes()) {
              // A shallow clone was previously appended, but now we need a deep clone.
              const deepClone = DOMUtils.cloneNode(node, true);
              // We reuse the existing element because it is already cached in indexOfRefs.
              existingElement.append(...deepClone.childNodes);
            }
            return existingElement;
          }
        } else if (DOMUtils.isElement(node.parentNode)) {
          // The node is most likely a text node, so we need to find its parent element.
          const existingParent = DOMUtils.findElement(node.parentNode, dest, true);
          // Check if the parent element was fully cloned.
          if (existingParent &amp;&amp; existingParent.childNodes.length === node.parentNode.childNodes.length) {
            return existingParent.childNodes[DOMUtils.indexOf(node)];
          }
        }

        // This node hasn't been appended yet.
        return originalAppend.apply(this, arguments);
      };

      layoutMethod.textBreak = function (node, start, end, vStart, vEnd) {
        let wordwalker = DOMUtils.words(node);
        let left = 0;
        let right = 0;
        let top = 0;
        let bottom = 0;
        let word, next, done, pos;
        let offset;
        while (!done) {
         next = wordwalker.next();
         word = next.value;
         done = next.done;

         if (!word) {
          break;
         }

         pos = Utils.getBoundingClientRect(word);

         left = Math.floor(pos.left);
         right = Math.floor(pos.right);
         top = Math.floor(pos.top);
         bottom = Math.floor(pos.bottom);

         if (left &gt;= end || top &gt;= vEnd) {
          // The word is completely outside the bounds of the print page. We need to break before it.
          offset = word.startOffset;
          break;
         }

         if (right &gt; end || bottom &gt; vEnd) {
          // The word is partially outside the print page (e.g. a word could be split / hyphenated on two lines of
          // text and only the first part fits into the current print page; or simply because the end of the page
          // truncates vertically the word). We need to see if any of its letters fit into the current print page.
          let letterwalker = DOMUtils.letters(word);
          let letter, nextLetter, doneLetter;

          while (!doneLetter) {
           // Note that the letter walker continues to walk beyond the end of the word, until the end of the
           // text node.
           nextLetter = letterwalker.next();
           letter = nextLetter.value;
           doneLetter = nextLetter.done;

           if (!letter) {
            break;
           }

           pos = Utils.getBoundingClientRect(letter);
           right = Math.floor(pos.right);
           bottom = Math.floor(pos.bottom);

           // Stop if the letter exceeds the bounds of the print page. We need to break before it.
           if (right &gt; end || bottom &gt; vEnd) {
            offset = letter.startOffset;
            done = true;

            break;
           }
          }
         }

        }

        // The returned value is used by findOverflow to set the start of the range used to delete the excess content
        // (that overflows the current print page). The problem is that findOverflow doesn't set the range start if
        // '!offset' which is obviously true when offset is 0. The workaround is to return instead the '0' string which
        // will pass the check, and then get converted automatically back to 0 by JavaScript when calling
        // range.setStart().
        return offset === 0 ? '0' : offset;
      };
    }
  }

  // The maxChars setting determines when to start looking for the overflow point. It it's too low it triggers too many
  // break point computations (which lead to a reflow and repain operation after adding each DOM node to a print page).
  // The maxChars setting should normally be set as the average char count for the last 4 print pages. In practice,
  // maxChars is set only once, based on the first print page, which can have very few chars if it's a cover page.
  //
  // TODO: Remove this code when https://github.com/pagedjs/pagedjs/issues/159 (maxChars is set only once, based on the
  // first print page, and then never updated) gets fixed.
  class FixMaxChars extends Paged.Handler {
    constructor(chunker, polisher, caller) {
      super(chunker, polisher, caller);
    }

    beforePageLayout(page) {
      const originalLayout = page.layout;
      page.layout = function(contents, breakToken, maxChars) {
        if (maxChars) {
          this.settings.maxChars = maxChars;
        }
        return originalLayout.apply(this, arguments);
      };
    }
  }

  Paged.registerHandlers(
    ShowInvisibleRowsOnPageBreaks,
    FixFloatingImages,
    FixTableLayout,
    FixMaxChars
  );

  return PagedPolyfill;
});

define('xwiki-export-pdf-config', ['jquery'], function($) {
  const pdfExportConfig = {
    documents: [],
    baseURL: window.location.href
  };
  try {
    Object.assign(pdfExportConfig, JSON.parse($('#pdfExportConfig').text()));
  } catch (e) {
    console.error(e);
  }
  return pdfExportConfig;
});

require([
  'jquery',
  'xwiki-page-ready',
  'xwiki-export-pdf-config'
], function($, pageReady, pdfExportConfig) {
  const refactorAnchors = function() {
    // Fix anchors that use relative URLs to point to the right document (that generated that anchor).
    fixRelativeAnchors($('#xwikicontent'));
    // Convert external anchors that target exported documents into internal anchor, whenever possible.
    pdfExportConfig.documents?.forEach?.(document =&gt; {
      const documentReference = XWiki.Model.resolve(document.reference, XWiki.EntityType.DOCUMENT,
        XWiki.currentDocument.documentReference);
      makeInternalAnchors($('#xwikicontent'), documentReference, document.idMap);
    });
    // The anchors in the PDF table of contents are already using global fragment identifiers.
    makeInternalAnchors($('.pdf-toc'), XWiki.currentDocument.documentReference);
  };

  /**
   * When exporting multiple documents to PDF each of them can produce anchors with relative URLs that are by default
   * resolved based on the current document used to trigger the PDF export, which is not what we want. Those relative
   * anchors should target the documents that generated them.
   *
   * @param container where to look for relative anchors that need to be fixed
   */
  const fixRelativeAnchors = function(container) {
    container.find('a[href]').each(function() {
      const anchor = $(this);
      let documentReference = anchor.parentsUntil(container).last().prevAll('h1[data-xwiki-document-reference]')
        .first().attr('data-xwiki-document-reference');
      if (documentReference) {
        documentReference = XWiki.Model.resolve(documentReference, XWiki.EntityType.DOCUMENT,
          XWiki.currentDocument.documentReference);
        const document = new XWiki.Document(documentReference);
        const documentURL = new URL(document.getURL(), pdfExportConfig.baseURL);
        try {
          anchor.attr('href', new URL(anchor.attr('href'), documentURL).href);
        } catch (e) {
          console.log('Failed to fix relative URL: ' + anchor.attr('href'));
        }
      }
    });
  };

  /**
   * Look for external anchors that target the specified document (which is included in the PDF export) and convert them
   * to internal anchors like this:
   * &lt;ul&gt;
   *   &lt;li&gt;/xwiki/bin/view/Path/To/Document =&gt; #documentTitleHeadingId&lt;/li&gt;
   *   &lt;li&gt;/xwiki/bin/view/Path/To/Document#localFragmentId =&gt; #globalFragmentId&lt;/li&gt;
   *   &lt;li&gt;/xwiki/bin/view/Path/To/Document#globalFragmentId =&gt; #globalFragmentId&lt;/li&gt;
   * &lt;/ul&gt;
   */
  const makeInternalAnchors = function(container, documentReference, idMap) {
    const document = new XWiki.Document(documentReference);
    const documentURL = new URL(document.getURL(), pdfExportConfig.baseURL).href;
    container.find('a[href]').each(function() {
      const anchor = $(this);
      try {
        const anchorURL = new URL(anchor.attr('href'), pdfExportConfig.baseURL);
        // Drop the '#' from the end of the URL when the hash is empty.
        anchorURL.hash = anchorURL.hash;
        if (anchorURL.href === documentURL + anchorURL.hash) {
          // Assume the anchor targets a document fragment specified by its global id.
          let fragmentId = anchorURL.hash.substring(1);
          if (!fragmentId) {
            // The anchor targets the start of the document.
            fragmentId = getDocumentFragmentId(documentReference);
          } else if (idMap) {
            // The anchor targets a document fragment specified by its local id.
            fragmentId = idMap[fragmentId];
          }
          if (fragmentId) {
            anchor.attr('href', '#' + fragmentId);
          }
        }
      } catch (e) {
        console.log('Failed to parse URL: ' + anchor.prop('href'));
      }
    });
  };

  /**
   * Search for the heading that marks the start of the specified document in the rendering output and return its id,
   * which can be used as a fragment identifier in internal links.
   *
   * @return the id of the heading that marks the start of the specified document
   */
  const getDocumentFragmentId = function(documentReference) {
    const stringDocRef = XWiki.Model.serialize(documentReference);
    return $('#xwikicontent &gt; h1[data-xwiki-document-reference]').filter(function() {
      return $(this).attr('data-xwiki-document-reference') === stringDocRef;
    }).attr('id');
  };

  const replaceCanvasesWithImages = function(container) {
    return $.makeArray(container.find('canvas')).reduce((replacePreviousCanvas, canvas) =&gt; {
      return replacePreviousCanvas.then(replaceCanvasWithImage.bind(null, canvas)).catch((e) =&gt; {
        console.log(`Failed to replace ${canvas.outerHTML} with image: ${e}`);
      });
    }, Promise.resolve());
  };

  // See https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/toBlob#getting_a_file_representing_the_canvas
  const objectURLs = [];
  const replaceCanvasWithImage = function(canvas) {
    return new Promise((resolve, reject) =&gt; {
      canvas.toBlob(blob =&gt; {
        const image = document.createElement('img'),
          url = URL.createObjectURL(blob);
        objectURLs.push(url);
        // Note that we don't revoke the object URL when the image is loaded because the image is going to be moved
        // within the DOM when paged.js generates the print layout. Firefox is smart enough to not reload moved images
        // but Chrome isn't and shows the broken image icon if the object URL was revoked since the image was loaded.
        // The solution is to collect the object URLs and revoke them only after the print layout is ready.
        image.onload = resolve;
        image.src = url;
        canvas.parentNode.replaceChild(image, canvas);
      }, 'image/png', 1);
    });
  };

  // Remove the Table of Contents if empty.
  const removeEmptyTableOfContents = function() {
    const toc = $('.pdf-toc');
    if (!toc.find('li').length) {
      toc.remove();
    }
  };

  /**
   * The anchors from the PDF table of contents must target existing sections within the PDF content, otherwise Paged.js
   * cannot compute the print page number where those sections appear, in order to show this to the right of the anchor.
   * Anchors that don't targer an existing section or that use an invalid section id are especially problematic because
   * they break Paged.js (e.g. "Failed to execute 'querySelector' on 'Element': '#...' is not a valid selector"). We
   * mark the invalid table of contents anchors in order to skip them when determining the page number, otherwise we
   * would get 0 which is misleading. Of course, the code that generates those invalid anchors should to be fixed also.
   */
  const validateTableOfContentsAnchors = function() {
    $('.pdf-toc ul a[href]').each(function() {
      const target = $(this).attr('href');
      try {
        // We replicate the behavior of Paged.js which performs CSS escaping before calling querySelector. The problem
        // is that it does CSS escaping using an internal querySelectorEscape function that we can't access. Instead of
        // duplicating the code we rely on the standard CSS#escape function which should lead to similar results.
        if (document.querySelector(querySelectorEscape(target))) {
          // Valid anchor. Don't touch it.
          return;
        } else {
          console.warn('Missing section expected by the PDF table of contents: ' + target);
        }
      } catch (e) {
        console.warn('Invalid anchor in PDF table of contents: ' + target);
      }
      $(this).removeAttr('href').attr('data-invalid-href', target);
    });
  };

  const querySelectorEscape = function(value) {
    // querySelectorEscape from Paged.js doesn't escape # (Hash) and . (Dot, when the string doesn't start with #) so we
    // need to do the same. Replace # (Hash) and . (Dot) with _ (Underscore) in order to not escape them.
    const escapeIndex = [];
    const doesNotStartWithHash = value.charAt(0) !== '#';
    let escapedValue = [...value].map(char =&gt; {
      if (char === '_' || char === '#' || (doesNotStartWithHash &amp;&amp; char === '.')) {
        escapeIndex.push(char);
        return '_';
      }
      return char;
    }).join('');
    escapedValue = CSS.escape(escapedValue);
    // Restore the # (Hash) and . (Dot) that were previously replaced with _ (Underscore).
    let escapeCount = 0;
    return [...escapedValue].map(char =&gt; {
      if (char === '_') {
        return escapeIndex[escapeCount++];
      }
      return char;
    }).join('');
  };

  /**
   * Form field values that are set by the user after the page is loaded are lost when the fields are detached from the
   * DOM. This happens for instance when Paged.js splits the exported content into print pages and adds its wrappers
   * around each of these print pages. In order to overcome this we store the form field values in the DOM (e.g. using
   * the value attribute) so they are preserved when the form fields are moved around inside the DOM document.
   */
  const storeFormFieldValues = function() {
    $('input').filter(':visible').each(function() {
      this.setAttribute('value', this.value);
    });
    $('input[type="checkbox"], input[type="radio"]').filter(':visible').each(function() {
      this.toggleAttribute('checked', this.checked);
    });
    $('textarea').filter(':visible').each(function() {
      this.textContent = this.value;
    });
    $('option').each(function() {
      this.toggleAttribute('selected', this.selected);
    });
  };

  /**
   * Tables with absolute column / cell widths are printed very badly. There's not much we can do about it besides
   * trying to replace the absolute widths with relative widths. Besides that, even if the column / cell width is not
   * specified it's still good to set it to a relative value in order to ensure that when a table is split between print
   * pages then the layout is preserved from one page to the next.
   */
  const makeTableCellWidthRelative = function() {
    // Remove temporarily the maximum width limitation from the table in order to compute the cell width relative to the
    // full table width. Otherwise the cell width could be influenced by the screen width.
    $('#xwikicontent table').each(function() {
      this.__pdfExport_maxWidth = this.style.getPropertyValue('max-width');
      this.style.setProperty('max-width', 'none');
    });

    // If the table cell width is specified then replace its value with the corresponding percentage of the table width.
    // If the cell width is not specified we still set it to a relative value in order to preserve the layout when the
    // table is split between print pages.
    $('#xwikicontent th, #xwikicontent td').each(function() {
      const specifiedCellWidth = this.style.getPropertyValue('width') || this.getAttribute('width');
      if (!specifiedCellWidth || !specifiedCellWidth.trimEnd().endsWith('%')) {
        const computedCellWidth = this.clientWidth;
        const rowWidth = this.parentNode.clientWidth;
        const relativeCellWidth = Math.floor(computedCellWidth / rowWidth * 10000) / 100;
        // We update the width at the end, after computing all relative cell widths, in order to trigger a single reflow
        // and repaint operation, which is an expensive opration. Otherwise we would trigger one reflow and repaint for
        // each table cell (because setting the width invalidates the clientWidth cache), which would slow the page
        // load, eventually triggering the page ready timeout.
        // See  https://dev.to/gopal1996/understanding-reflow-and-repaint-in-the-browser-1jbg
        $(this).attr('data-xwiki-pdf-export-relative-width', relativeCellWidth + '%');
      }
    });

    // Update the cell widths to be relative (triggering a single reflow and repaint).
    $('[data-xwiki-pdf-export-relative-width]').each(function() {
      $(this).css({width: $(this).attr('data-xwiki-pdf-export-relative-width')});
    }).removeAttr('width data-xwiki-pdf-export-relative-width');

    // Remove any width set on the table itself. This width is most probably the result of a table resize performed from
    // the WYSIWYG editor. But since the XWiki skin is making tables use the full available width by default (width:
    // 100%) chances are that the table resize done from the WYSIWYG editor has no effect on view mode so it shouldn't
    // have any effect on the PDF export either.
    $('#xwikicontent table').removeAttr('width').css({width: ''}).each(function() {
      // Restore the maximum width limitation.
      this.style.setProperty('max-width', this.__pdfExport_maxWidth);
    });
  };

  const preserveWhiteSpaceInCodeBlocks = () =&gt; {
    // Paged.js removes / skips the white-space-only text nodes that are direct children of a block element (a DIV in
    // our case) even if that element asks for white-space to be preserved (through CSS). The workaround we apply here
    // is to wrapp all these white-space-only text nodes with a SPAN (so their parent is not a block element anymore).
    // See XWIKI-20553: The whitespace between two highlighted code tokens is lost when exporting to PDF
    // See also https://github.com/pagedjs/pagedjs/issues/45
    $('#xwikicontent div.box &gt; div.code').contents().filter(function() {
      return this.nodeType === 3;
    }).wrap("&lt;span&gt;&lt;/span&gt;");
  };

  /**
   * Removes the image size (width and height) from the image URL query string in order to prevent the server-side
   * resize of the image, thus allowing the full size image to be included in the generated PDF.
   */
  async function disableServerSideImageResize() {
    const imageLoadPromises = []
    document.querySelectorAll('#xwikicontent img:not(.force-server-side-resize)').forEach(image =&gt; {
      const imageURL = new URL(image.src);
      const imageParams = imageURL.searchParams;
      if (imageParams.has('width') || imageParams.has('height')) {
        // Backup the original query string before we modify the image URL.
        const oldImageQueryString = imageURL.search;
        // The image size is specified in the URL which may trigger a server-side resize. We want the full image to be
        // included in the PDF so let's remove these parameters.
        imageParams.delete('width');
        imageParams.delete('height');
        const newImageQueryString = '?' + imageParams.toString();
        const newImageSrc = image.getAttribute('src').replace(oldImageQueryString, newImageQueryString);
        // Create a promise for when the full size image is loaded.
        imageLoadPromises.push(new Promise((resolve, reject) =&gt; {
          image.addEventListener('load', resolve);
          image.addEventListener('error', reject);
          image.addEventListener('abort', resolve);
          image.setAttribute('src', newImageSrc);
        }));
      }
    });
    await Promise.allSettled(imageLoadPromises);
  }

  pageReady.delayPageReady(disableServerSideImageResize(), 'Disable server-side image resize.');

  // Adjust the exported content before performing the print layout.
  pageReady.afterPageReady(() =&gt; {
    refactorAnchors();
    removeEmptyTableOfContents();
    validateTableOfContentsAnchors();
    storeFormFieldValues();
    makeTableCellWidthRelative();
    preserveWhiteSpaceInCodeBlocks();
  });

  // Trigger the print preview after the page is ready. Note that by returning a promise we're making the next page
  // ready callbacks wait for the print preview to be ready. This is important in case one of the next page ready
  // callbacks triggers the print.
  pageReady.afterPageReady(() =&gt; {
    // We don't need Paged.js (the polyfill for CSS Paged Media module) unless the user asked for a table of contents,
    // headers or footers (which require the Paged Media module).
    const usePagedPolyfill = $('body').children('.pdf-toc, .pdf-header, .pdf-footer').length;
    if (usePagedPolyfill) {
      return new Promise((resolve, reject) =&gt; {
        window.PagedConfig = {after: resolve};
        // Replace each canvas with an image before paged.js layouts the print pages, otherwise all canvases become
        // blank when they are moved around within the DOM tree.
        replaceCanvasesWithImages($('#xwikicontent')).catch((cause) =&gt; {
          console.log('Failed to replace canvases with images. Cause: ' + cause);
        }).finally(() =&gt; {
          require(['paged-polyfill'], function(PagedPolyfill) {});
        })
      });
    }
  });

  pageReady.afterPageReady(() =&gt; {
    // Revoke the object URLs previously created, after the print layout is ready.
    objectURLs.forEach(url =&gt; URL.revokeObjectURL(url));

    // Sets the base URL used to resolve relative URLs in the exported content. When the base URL is not set the
    // relative URLs are by default resolved relative to the print preview URL which uses the export action and has a
    // long query string that is specific to PDF export. This means relative URLs may be resolved using the export
    // action and some strange query string if the base URL is not set. We set the base URL after the page is ready
    // because we don't want to influence resource loading (images, CSS, JavaScript). This is especially important when
    // the PDF is printed using a remote web browser (e.g. running inside a Docker container) in which case the URL used
    // to access the print preview page can be different than the URL used by the user to trigger the PDF export (i.e.
    // the base URL). We want the base URL to be taken into account only when resolving relative links in the generated
    // PDF.
    $('&lt;base/&gt;').attr('href', pdfExportConfig.baseURL).prependTo('head');
  });
});</code>
    </property>
    <property>
      <name/>
    </property>
    <property>
      <parse>0</parse>
    </property>
    <property>
      <use>onDemand</use>
    </property>
  </object>
  <object>
    <name>XWiki.PDFExport.Sheet</name>
    <number>0</number>
    <className>XWiki.StyleSheetExtension</className>
    <guid>141c16dd-091a-4b59-96cd-d63132aeeb41</guid>
    <class>
      <name>XWiki.StyleSheetExtension</name>
      <customClass/>
      <customMapping/>
      <defaultViewSheet/>
      <defaultEditSheet/>
      <defaultWeb/>
      <nameField/>
      <validationScript/>
      <cache>
        <cache>0</cache>
        <defaultValue>long</defaultValue>
        <disabled>0</disabled>
        <displayType>select</displayType>
        <freeText>forbidden</freeText>
        <largeStorage>0</largeStorage>
        <multiSelect>0</multiSelect>
        <name>cache</name>
        <number>5</number>
        <prettyName>Caching policy</prettyName>
        <relationalStorage>0</relationalStorage>
        <separator> </separator>
        <separators>|, </separators>
        <size>1</size>
        <unmodifiable>0</unmodifiable>
        <values>long|short|default|forbid</values>
        <classType>com.xpn.xwiki.objects.classes.StaticListClass</classType>
      </cache>
      <code>
        <contenttype>PureText</contenttype>
        <disabled>0</disabled>
        <editor>PureText</editor>
        <name>code</name>
        <number>2</number>
        <prettyName>Code</prettyName>
        <restricted>0</restricted>
        <rows>20</rows>
        <size>50</size>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.TextAreaClass</classType>
      </code>
      <contentType>
        <cache>0</cache>
        <disabled>0</disabled>
        <displayType>select</displayType>
        <freeText>forbidden</freeText>
        <largeStorage>0</largeStorage>
        <multiSelect>0</multiSelect>
        <name>contentType</name>
        <number>6</number>
        <prettyName>Content Type</prettyName>
        <relationalStorage>0</relationalStorage>
        <separator> </separator>
        <separators>|, </separators>
        <size>1</size>
        <unmodifiable>0</unmodifiable>
        <values>CSS|LESS</values>
        <classType>com.xpn.xwiki.objects.classes.StaticListClass</classType>
      </contentType>
      <name>
        <disabled>0</disabled>
        <name>name</name>
        <number>1</number>
        <prettyName>Name</prettyName>
        <size>30</size>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.StringClass</classType>
      </name>
      <parse>
        <disabled>0</disabled>
        <displayFormType>select</displayFormType>
        <displayType>yesno</displayType>
        <name>parse</name>
        <number>4</number>
        <prettyName>Parse content</prettyName>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.BooleanClass</classType>
      </parse>
      <use>
        <cache>0</cache>
        <disabled>0</disabled>
        <displayType>select</displayType>
        <freeText>forbidden</freeText>
        <largeStorage>0</largeStorage>
        <multiSelect>0</multiSelect>
        <name>use</name>
        <number>3</number>
        <prettyName>Use this extension</prettyName>
        <relationalStorage>0</relationalStorage>
        <separator> </separator>
        <separators>|, </separators>
        <size>1</size>
        <unmodifiable>0</unmodifiable>
        <values>currentPage|onDemand|always</values>
        <classType>com.xpn.xwiki.objects.classes.StaticListClass</classType>
      </use>
    </class>
    <property>
      <cache>long</cache>
    </property>
    <property>
      <code>//
// Grid system for print media
//
@print-margin: 1in;
// We change the values of the following standard Bootstrap variables to match standard paper sizes.
@screen-sm-min: floor(((210mm - @print-margin) * .75)); // A4 (portrait)
@screen-md-min: floor(((297mm - @print-margin) * .75)); // A4 (landscape)
@screen-lg-min: floor(((420mm - @print-margin) * .75)); // A3 (landscape)

// Small grid
//
// Columns, offsets, pushes, and pulls for the A4 portrait format.

@media print and (min-width: @screen-sm-min) {
  .make-grid(sm);
}

// Medium grid
//
// Columns, offsets, pushes, and pulls for the A4 landscape format.

@media print and (min-width: @screen-md-min) {
  .make-grid(md);
}

// Large grid
//
// Columns, offsets, pushes, and pulls for the A3 landscape format.

@media print and (min-width: @screen-lg-min) {
  .make-grid(lg);
}

//
// Print styles
//
@media print {
  /**
   * Standard Page
   */
  @page {
    size: A4;
    margin: (@print-margin / 2);
    padding: .2in 0;

    /* Header */
    @top-center {
      content: element(header);
    }

    /* Footer */
    @bottom-center {
      content: element(footer);
    }
  }

  .pdf-header,
  .pdf-footer {
    color: @text-muted;
  }

  .pdf-header {
    position: running(header);
  }

  .pdf-footer {
    position: running(footer);
  }

  .pdf-page-number::after {
    content: counter(page);
  }
  .pdf-page-count::after {
    content: counter(pages);
  }

  /**
   * Landscape Page
   */
  @page landscape {
    size: A4 landscape;
  }

  .page-landscape {
    page: landscape;
  }

  /**
   * Cover Page
   */
  @page cover {
    @top-center {
      /* Hide the header on the cover page. */
      content: none;
    }

    @bottom-center {
      /* Hide the footer on the cover page. */
      content: none;
    }
  }

  .pdf-cover {
    page: cover;
  }

  /**
   * Table of Contents
   */
  @page toc {
  }

  .pdf-toc {
    page: toc;
  }

  .pdf-toc ul {
    list-style: none;
    padding-left: .2in
  }
  .pdf-toc &gt; ul {
    padding-left: 0;
  }

  .pdf-toc li {
    margin: .5em 0;
    /* Make sure the fake dotted leader doesn't overflow. */
    overflow-x: hidden;
  }
  .pdf-toc &gt; ul &gt; li &gt; span {
    font-size: 110%;
  }

  /* Fake dotted leader, see https://pagedjs.org/post/toc/ */
  .pdf-toc li &gt; span::after {
    content:
      ".............................................."
      ".............................................."
      ".............................................."
      "........";
    float: left;
    width: 0;
    letter-spacing: 2px;
  }

  /* Section title */
  .pdf-toc ul a {
    /* Make sure the leader dots are not displayed beneath the section title. */
    background-color: white !important;
    padding-right: .5em;
  }

  /* Page number */
  .pdf-toc ul a[href]::after {
    content: target-counter(attr(href), page);
    /* For the fake dotted leader. */
    position: absolute;
    right: 0;
    /* Make sure the leader dots are not displayed beneath the page number */
    background-color: white !important;
    padding-left: .5em;
  }

  /**
   * Content
   */
  /* Browsers try to improve the contrast in order to generate print-friendly PDFs and for this they change the colors
    we specify in CSS. The following rules tell the browser to preserve our colors. */
  html:not([data-xwiki-paged-media=paper]) * {
    -webkit-print-color-adjust: exact;
    print-color-adjust: exact;
  }

  /* Remove styles that don't make much sense when printing to PDF. */
  body {
    background-color: unset;
  }
  *, *:before, *:after {
    /* Box shadows don't look good in PDF. */
    box-shadow: none !important;
  }

  table {
    /* Tables need to fit the available page width otherwise paged.js has a hard time splitting them on multiple print
      pages. Tables that exceed both the page width and the page height cause an infinite loop in paged.js (leads to the
      creation of an infinite number of print pages). Tables that exceed only the page height are fine. The solution we
      choose is to make sure that the table text can always be split (hyphenate) on multiple lines. This is not a
      complete solution but it should cover most of the large tables. */
    .hyphenate();
  }

  // Make sure the content of the code macro is not cut when it exceeds the print page width by:
  div.code {
    // decreasing the font size when printing
    font-size: 80%;
  }
  div.code, div.code * {
    // and wrapping long lines, while still preserving the whitespace.
    white-space: pre-wrap;
  }
  div.box &gt; div.code &gt; pre {
    margin: 0;
  }
}</code>
    </property>
    <property>
      <contentType>LESS</contentType>
    </property>
    <property>
      <name/>
    </property>
    <property>
      <parse>0</parse>
    </property>
    <property>
      <use>onDemand</use>
    </property>
  </object>
  <object>
    <name>XWiki.PDFExport.Sheet</name>
    <number>0</number>
    <className>XWiki.UIExtensionClass</className>
    <guid>68c24782-b67b-4c25-b004-868783d31b2b</guid>
    <class>
      <name>XWiki.UIExtensionClass</name>
      <customClass/>
      <customMapping/>
      <defaultViewSheet/>
      <defaultEditSheet/>
      <defaultWeb/>
      <nameField/>
      <validationScript/>
      <async_cached>
        <defaultValue>0</defaultValue>
        <disabled>0</disabled>
        <displayFormType>select</displayFormType>
        <displayType/>
        <name>async_cached</name>
        <number>3</number>
        <prettyName>Cached</prettyName>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.BooleanClass</classType>
      </async_cached>
      <async_context>
        <cache>0</cache>
        <disabled>0</disabled>
        <displayType>select</displayType>
        <freeText>forbidden</freeText>
        <largeStorage>0</largeStorage>
        <multiSelect>1</multiSelect>
        <name>async_context</name>
        <number>4</number>
        <prettyName>Context elements</prettyName>
        <relationalStorage>0</relationalStorage>
        <separator>, </separator>
        <separators>|, </separators>
        <size>5</size>
        <unmodifiable>0</unmodifiable>
        <values>action=Action|doc.reference=Document|icon.theme=Icon theme|locale=Language|rendering.defaultsyntax=Default syntax|rendering.restricted=Restricted|rendering.targetsyntax=Target syntax|request.base=Request base URL|request.cookies|request.headers|request.parameters=Request parameters|request.remoteAddr|request.url=Request URL|request.wiki=Request wiki|user=User|wiki=Wiki</values>
        <classType>com.xpn.xwiki.objects.classes.StaticListClass</classType>
      </async_context>
      <async_enabled>
        <defaultValue>0</defaultValue>
        <disabled>0</disabled>
        <displayFormType>select</displayFormType>
        <displayType/>
        <name>async_enabled</name>
        <number>2</number>
        <prettyName>Asynchronous rendering</prettyName>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.BooleanClass</classType>
      </async_enabled>
      <content>
        <disabled>0</disabled>
        <editor>Text</editor>
        <name>content</name>
        <number>1</number>
        <prettyName>Executed Content</prettyName>
        <restricted>0</restricted>
        <rows>25</rows>
        <size>120</size>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.TextAreaClass</classType>
      </content>
      <extensionPointId>
        <disabled>0</disabled>
        <name>extensionPointId</name>
        <number>5</number>
        <prettyName>Extension Point ID</prettyName>
        <size>30</size>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.StringClass</classType>
      </extensionPointId>
      <name>
        <disabled>0</disabled>
        <name>name</name>
        <number>6</number>
        <prettyName>Extension ID</prettyName>
        <size>30</size>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.StringClass</classType>
      </name>
      <parameters>
        <contenttype>PureText</contenttype>
        <disabled>0</disabled>
        <editor>PureText</editor>
        <name>parameters</name>
        <number>7</number>
        <prettyName>Extension Parameters</prettyName>
        <restricted>0</restricted>
        <rows>10</rows>
        <size>40</size>
        <unmodifiable>0</unmodifiable>
        <classType>com.xpn.xwiki.objects.classes.TextAreaClass</classType>
      </parameters>
      <scope>
        <cache>0</cache>
        <disabled>0</disabled>
        <displayType>select</displayType>
        <freeText>forbidden</freeText>
        <largeStorage>0</largeStorage>
        <multiSelect>0</multiSelect>
        <name>scope</name>
        <number>8</number>
        <prettyName>Extension Scope</prettyName>
        <relationalStorage>0</relationalStorage>
        <separator> </separator>
        <separators>|, </separators>
        <size>1</size>
        <unmodifiable>0</unmodifiable>
        <values>wiki=Current Wiki|user=Current User|global=Global</values>
        <classType>com.xpn.xwiki.objects.classes.StaticListClass</classType>
      </scope>
    </class>
    <property>
      <async_cached>0</async_cached>
    </property>
    <property>
      <async_context/>
    </property>
    <property>
      <async_enabled>0</async_enabled>
    </property>
    <property>
      <content/>
    </property>
    <property>
      <extensionPointId>org.xwiki.platform.requirejs.module</extensionPointId>
    </property>
    <property>
      <name>org.xwiki.platform.export.pdf.module.paged-polyfill</name>
    </property>
    <property>
      <parameters>id=paged-polyfill
path=$services.webjars.url('org.webjars.npm:pagedjs', 'dist/paged.polyfill.js')</parameters>
    </property>
    <property>
      <scope>wiki</scope>
    </property>
  </object>
</xwikidoc>
